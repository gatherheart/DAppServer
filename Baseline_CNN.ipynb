{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Baseline_CNN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gatherheart/DAppServer/blob/master/Baseline_CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j3J8rf0_3xbQ",
        "colab_type": "text"
      },
      "source": [
        "# Machine Learning, Spring 2020, Final Project\n",
        "\n",
        "## Image Classification with Noisy Labels\n",
        "\n",
        "1. Download ```final_project.pdf```, ```Kaggle & Colab Guide.pptx```, and ```utils.py``` from i-campus.\n",
        "2. Go to [Kaggle competition page](https://www.naver.com), join Kaggle & competition, and download dataset.\n",
        "3. Following guide slides, upload ```utils.py```.\n",
        "4. Mount Google Drive.\n",
        "5. Implement your own model and predict on test images.\n",
        "6. Download and submit ```submission.csv``` to Kaggle.\n",
        "7. Write a report on your project and submit on i-campus."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uai9kBdn39Yy",
        "colab_type": "text"
      },
      "source": [
        "# INITIAL PACKAGES"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ByvGpuT3-9i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# INITIAL PACKAGES\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from time import time\n",
        "from utils import run"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hHanyOCm4C7M",
        "colab_type": "text"
      },
      "source": [
        "## Mount Google Drive\n",
        "\n",
        "Assmue you made ```final_project``` directory on the root,\n",
        "and data files are there."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aSHdZO_04BbZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "69fcbe05-a322-4e35-d727-15f439be9a38"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "17bcKUoX4Et_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "ced90582-0ade-4f26-d304-d998364d4170"
      },
      "source": [
        "gdrive_root = '/content/gdrive/My Drive'\n",
        "data_path = os.path.join(gdrive_root, 'HyunMuLab/Kaggle/ML_2020/final-project-introduction-to-ml-spring2020')\n",
        "print(data_path)\n",
        "os.listdir(data_path)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive/HyunMuLab/Kaggle/ML_2020/final-project-introduction-to-ml-spring2020\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['sample_submission.csv',\n",
              " 'test_images.pkl',\n",
              " 'train_data.pkl',\n",
              " 'valid_data.pkl']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jN9YeqHW4GF2",
        "colab_type": "text"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q_6Bt0kN4HUc",
        "colab_type": "text"
      },
      "source": [
        "# SHOW YOUR WORK\n",
        "From here, import packages you need as long as they are permitted. <br>\n",
        "Fill ```train_and_predict``` function with your codes. <br>\n",
        "If you want, you can implement your own classes or functions within \"SHOW YOUR WOKR\" block. <br>\n",
        "The rest of work is ours."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z6g1L4_w4JOg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# IMPORT PACKAGES YOU NEED\n",
        "import numpy as np\n",
        "from utils import run\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "import copy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QQ_gUkVd4MZU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# YOUR OWN CLASSES OR FUNCTIONS\n",
        "\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "\n",
        "        self.cnn_layers = nn.Sequential( # 8 CNN layers in total\n",
        "            nn.Conv2d(3, 128, 3, 1, 1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.LeakyReLU(negative_slope=0.01),\n",
        "            nn.Conv2d(128, 128, 3, 1, 1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.LeakyReLU(negative_slope=0.01),\n",
        "            nn.Conv2d(128, 256, 3, 1, 1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.LeakyReLU(negative_slope=0.01),\n",
        "            nn.MaxPool2d(2,2),\n",
        "            nn.Dropout2d(p=0.25), # 3-layers\n",
        "            nn.Conv2d(256, 256, 3, 1, 1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.LeakyReLU(negative_slope=0.01),\n",
        "            nn.Conv2d(256, 256, 3, 1, 1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.LeakyReLU(negative_slope=0.01),\n",
        "            nn.Conv2d(256, 512, 3, 1, 1),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.LeakyReLU(negative_slope=0.01),\n",
        "            nn.MaxPool2d(2,2),\n",
        "            nn.Dropout2d(p=0.25),\n",
        "            nn.Conv2d(512, 256, 3, 1, 1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.LeakyReLU(negative_slope=0.01),\n",
        "            nn.Conv2d(256, 256, 3, 1, 1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.LeakyReLU(negative_slope=0.01),\n",
        "            nn.MaxPool2d(2,2)\n",
        "        )\n",
        "\n",
        "        self.linear = nn.Linear(4096, 14)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.cnn_layers(x)\n",
        "        x = self.linear(x.view(x.shape[0], -1))\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QiGBLA-k4O7M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_and_predict(train_data, valid_data, test_images):\n",
        "    \"\"\"Train a model and return prediction on test images.\n",
        "\n",
        "    Given train and valid data, build your model and optimize.\n",
        "    Then, return predictions on test_images.\n",
        "\n",
        "    You can import packages you want inside 'EDIT HERE' as long as they are permitted.\n",
        "    (See document for the list of possible packages)\n",
        "\n",
        "    arguments:\n",
        "        train_data: tuple of (pandas.DataFrame, np.array).\n",
        "        - 0: pandas.DataFrame with columns ['id', 'label']\n",
        "          'id' contains unique id assigned to each image.\n",
        "          'label' contains label (0 ~ # classes-1) corresponding to its image.\n",
        "        - 1: train image in np.array of (# train data, # channel, height, width)\n",
        "\n",
        "        valid_data: tuple of (pandas.DataFrame, np.array).\n",
        "        - 0: pandas.DataFrame with columns ['id', 'label']\n",
        "          'id' contains unique id assigned to each image.\n",
        "          'label' contains label (0 ~ # classes-1) corresponding to its image.\n",
        "        - 1: valid image in np.array of (# valid data, # channel, height, width)\n",
        "\n",
        "        test_data: tuple of (pandas.DataFrame, np.array).\n",
        "        - 0: pandas.DataFrame with columns ['id']\n",
        "          'id' contains unique id assigned to each image.\n",
        "        - 1: test image in np.array of (# test data, # channel, height, width)\n",
        "    \n",
        "    returns:\n",
        "        pandas.DataFrame, predictions on test images with columns ['id', 'label'].\n",
        "        'id' should contain unique id assigned to test images. \n",
        "        'label' should contain prediction on the test image correspond to its id\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "    LEARNING_RATE = 0.001\n",
        "    BATCH_SIZE = 256\n",
        "    TEST_BATCH_SIZE = 1024\n",
        "    NUM_EPOCHS = 150\n",
        "    PATIENCE = 10\n",
        "    ENDURE = 0\n",
        "\n",
        "    train_id_label, train_images = train_data['label'], train_data['image']\n",
        "    valid_id_label, valid_images = valid_data['label'], valid_data['image']\n",
        "    test_id, _test_images = test_images['id'], test_images['image']\n",
        "\n",
        "    num_train = len(train_images)\n",
        "    num_valid = len(valid_images)\n",
        "    num_test = len(test_images)\n",
        "    \n",
        "    # Convert data into torch.Tensor\n",
        "    x_train = torch.FloatTensor(train_images)\n",
        "    y_train = train_id_label['label'].values\n",
        "    y_train = torch.LongTensor(y_train)\n",
        "\n",
        "    x_valid = torch.FloatTensor(valid_images)\n",
        "    y_valid = valid_id_label['label'].values\n",
        "    y_valid = torch.LongTensor(y_valid)\n",
        "\n",
        "    x_test = torch.FloatTensor(_test_images)\n",
        "\n",
        "    num_features = np.prod(x_train.shape[1:])\n",
        "    num_classes = int(y_train.max()) + 1\n",
        "\n",
        "    # Build torch dataset, dataloader\n",
        "    train_dataset = TensorDataset(x_train, y_train)\n",
        "    valid_dataset = TensorDataset(x_valid, y_valid)\n",
        "    test_dataset = TensorDataset(x_test)\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "    valid_loader = DataLoader(valid_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=TEST_BATCH_SIZE, shuffle=False)\n",
        "\n",
        "    # Build CNN model\n",
        "    model = CNN().to(device)\n",
        "\n",
        "    # Optimizer and loss function\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
        "    loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "\n",
        "    # Train model\n",
        "    mean_train_losses = []\n",
        "    mean_valid_losses = []\n",
        "    valid_acc_list = []\n",
        "    best_acc = -1\n",
        "\n",
        "    train_s = time()\n",
        "    for epoch in range(1, NUM_EPOCHS + 1):\n",
        "        epoch_s = time()\n",
        "        model.train()\n",
        "        \n",
        "        train_losses = []\n",
        "        valid_losses = []\n",
        "        for i, (images, labels) in enumerate(train_loader):\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            \n",
        "            outputs = model(images)\n",
        "            loss = loss_fn(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            \n",
        "            train_losses.append(loss.item())\n",
        "            \n",
        "        model.eval()\n",
        "        \n",
        "        correct = 0\n",
        "        total = 0\n",
        "        # Disable gradient calculation for memory, computation efficiency\n",
        "        with torch.no_grad():\n",
        "            for i, (images, labels) in enumerate(valid_loader):\n",
        "                images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "                outputs = model(images)\n",
        "                loss = loss_fn(outputs, labels)\n",
        "                \n",
        "                valid_losses.append(loss.item())\n",
        "                \n",
        "                predicted = torch.argmax(outputs.data, 1)\n",
        "                correct += (predicted == labels).sum().item()\n",
        "                total += labels.size(0)\n",
        "                \n",
        "        mean_train_losses.append(np.mean(train_losses))\n",
        "        mean_valid_losses.append(np.mean(valid_losses))\n",
        "\n",
        "        epoch_elapsed = time() - epoch_s\n",
        "        \n",
        "        valid_acc = correct / total\n",
        "        valid_acc_list.append(valid_acc)\n",
        "        print('epoch: {}, train loss: {:.4f}, valid loss: {:.4f}, valid acc: {:.4f}, elapsed: {:.4f}'\\\n",
        "            .format(epoch, np.mean(train_losses), np.mean(valid_losses), valid_acc, epoch_elapsed))\n",
        "        \n",
        "        if best_acc < valid_acc:\n",
        "            print('Best Accuracy updated (%.4f => %.4f)' % (best_acc, valid_acc))\n",
        "            best_acc = valid_acc\n",
        "            best_epoch = epoch\n",
        "            ENDURE = 0\n",
        "            # Save best model\n",
        "            torch.save(model.state_dict(), 'best_mlp.p')\n",
        "        else:\n",
        "            ENDURE += 1\n",
        "            if ENDURE >= PATIENCE:\n",
        "                print('Early stop triggered...!')\n",
        "                break\n",
        "    train_elapsed = time() - train_s\n",
        "\n",
        "    print('Training Finished...!!')\n",
        "    print('Time: %.4f' % train_elapsed)\n",
        "    print('Best Valid acc : %.4f at epoch %d' % (best_acc, best_epoch))\n",
        "    \n",
        "    # Load best model\n",
        "    model.load_state_dict(torch.load('best_mlp.p'))\n",
        "    model.eval()\n",
        "\n",
        "    # Make prediction on test data\n",
        "    test_preds = []\n",
        "    with torch.no_grad():\n",
        "        for i, (images, ) in enumerate(test_loader):\n",
        "            images = images.to(device)\n",
        "\n",
        "            outputs = model(images)\n",
        "            \n",
        "            pred = outputs.argmax(1)\n",
        "\n",
        "            if device == 'cuda':\n",
        "                test_preds += pred.detach().cpu().numpy().tolist()\n",
        "            else:\n",
        "                test_preds += pred.detach().numpy().tolist()\n",
        "    \n",
        "    # Return prediction\n",
        "    test_images['label'] = test_preds\n",
        "    pred = test_images.loc[:, ['id', 'label']]\n",
        "\n",
        "    return pred"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lBuVAqj24th0",
        "colab_type": "text"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Smb8cWwe4uXe",
        "colab_type": "text"
      },
      "source": [
        "# YOUR WORK IS DONE!\n",
        "Do not touch any line below. <br>\n",
        "```run``` function will grap your prediction and make ```submission.csv```. <br>\n",
        "Take it and submit to Kaggle!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-1qvWcYs4w7y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "run(train_and_predict, data_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BsBbON-1F8Uc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 184
        },
        "outputId": "d3a44e27-e4d4-4ed1-a620-e7b3768066bb"
      },
      "source": [
        "train_data"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-6a115dfddf45>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'train_data' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R8867RuWGbjL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data = pd.read_pickle(os.path.join(data_path, 'train_data.pkl'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LCmeJ9jUGhQV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "_, label, image = train_data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tRJJmSvCGjtL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 368
        },
        "outputId": "fa815d63-68b2-4f96-9774-99530f998437"
      },
      "source": [
        "import time\n",
        "\n",
        "import torch\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "from pykeops.torch import LazyTensor\n",
        "\n",
        "use_cuda = torch.cuda.is_available()\n",
        "dtype = 'float32' if use_cuda else 'float64'\n",
        "torchtype = {'float32': torch.float32, 'float64': torch.float64}"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-48b8e10e60f2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpykeops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtorch\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLazyTensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0muse_cuda\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pykeops'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U8UwashWG9LM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_images = pd.read_pickle(os.path.join(data_path, 'test_images.pkl'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aRrt0-ZkH6G4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "_id, image = test_images"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zvc5r3YjH7QO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "t, a = test_images"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uHBAt6NqIvZc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "fb4ed2cc-f7f4-448c-b669-3447d48d8d28"
      },
      "source": [
        "a"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'image'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TKVxRZQQIzp9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "5e7c15ce-3966-4e43-d5ea-b1cdf4389b6c"
      },
      "source": [
        "test_images['image']"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "27602    [[[[0.67843139 0.68627453 0.67843139 0.6941176...\n",
              "5011     [[[[0.89803922 0.90196079 0.90588236 0.9058823...\n",
              "2070     [[[[0.89411765 0.80000001 0.87058824 0.7529411...\n",
              "11760    [[[[0.59215689 0.6156863  0.61960787 0.5647059...\n",
              "7065     [[[[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. ...\n",
              "                               ...                        \n",
              "26929    [[[[0.98823529 0.98823529 0.98823529 0.9882352...\n",
              "27732    [[[[1.         1.         1.         1.       ...\n",
              "12039    [[[[0.65490198 0.82352942 0.52549022 0.6196078...\n",
              "2231     [[[[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. ...\n",
              "15612    [[[[0.52156866 0.52941179 0.56470591 0.4666666...\n",
              "Name: image, Length: 10000, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rCUELOyUI05u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "    valid_data = pd.read_pickle(os.path.join(data_path, 'valid_data.pkl'))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dwKgowboJGC3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "_, a, b = valid_data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "smL5QdzXJHot",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ef5b0d22-1912-4d6d-dec8-eca939c890c8"
      },
      "source": [
        "b"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'label'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZZgVnMiSJH-u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}